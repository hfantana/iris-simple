{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Iris Classification Challenge\n",
    "\n",
    "##### Based on a notebook by [Randal S. Olson](http://www.randalolson.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal: Work through a simple machine learning example from start to finish along a typical data analysis pipeline. \n",
    "\n",
    "We will apply machine learning to a classification task and use a slightly modified version of the famous [Iris data set](https://archive.ics.uci.edu/ml/datasets/Iris). These data were collected by botanist Edward Anderson and popularized by the statistician Ronald Fisher in his classic 1936 paper, \"The use of multiple measurements in taxonomic problems\". Anderson measured the properties of three different species of iris flowers. The data set contains four features from each sample: the length and width of the petals and sepals, in centimeters. \n",
    "\n",
    "<img src=\"images/iris_petal_sepal.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "**Please note**: This exercise is based on a Jupyter notebook, an interactive environment for writing and running code, and is running in Python. To get familiar with working in Jupyter notebooks, see our JupyterLab Tutorial. For a short introduction to the basics of programming in Python, see the \"Introduction to Python\" notebook.\n",
    "\n",
    "<mark>Yellow highlights indicate a small exercise or task for you to try out.</mark>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">A cell like this indicates a question you need to answer for this Challenge on the U4I platform.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "0. [Introduction](#Introduction)\n",
    "\n",
    "1. [Step 1: Frame the problem](#Step-1:-Frame-the-problem) \n",
    "\n",
    "2. [Step 2: Check the data](#Step-2:-Check-the-data)\n",
    "\n",
    "3. [Step 3: Tidy the data](#Step-3:-Tidy-the-data)\n",
    "\n",
    "4. [Step 4: Exploratory analysis](#Step-4:-Exploratory-analysis)\n",
    "\n",
    "5. [Step 5: Classification](#Step-5:-Classification)\n",
    "\n",
    "6. [Step 6: Evaluation with cross-validation](#Step-6:-Evaluation-with-cross-validation)\n",
    "\n",
    "7. [Sources](#Sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "Let's pretend we would like to create a smartphone app that automatically identifies species of flowers from pictures taken on the smartphone. \n",
    "\n",
    "Our task is to create a demo machine learning model that **takes four measurements from flowers** (petal length, petal width, sepal length, and sepal width) and **identifies the species based on these measurements** alone. \n",
    "\n",
    "To develop the demo, we've been given a [data set](iris-data.csv) which includes measurements for three types of *Iris* flowers: Iris versicolor, Iris setosa, and Iris virginica.\n",
    "\n",
    "<img src=\"images/iris-types.png\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Frame the problem \n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "The first step to any data analysis project is to define the question or problem we're trying to solve, and to define a measure (or set of measures) for our success at solving that task. Here, we're trying to classify the species (i.e., class) of Iris flowers based on four measurements: sepal length, sepal width, petal length, and petal width. To quantify how well our model is performing, we look at the fraction of correctly classified flowers and aim to achieve at least 90% accuracy. \n",
    "\n",
    "When dealing with data, we need to always consider the experimental design, and what we can expect to answer with the available data. The data we're using come from hand-measurements of 50 randomly-sampled flowers of each species using a standardized methodology. Our measurements only include three types of *Iris* flowers. The model trained on this data set will thus also only work for Iris flowers, and we will need more data to create a general flower classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check the data\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "The next step is to look closer at the data we're working with. Spotting potential errors in the data set early can save a lot of time during our later analysis. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Question 1: What might be one reason for spotting potential errors in the data before using it to create a model?</div>\n",
    "\n",
    "<mark>Double-click on the \"iris-data.csv\" file to view the data in a separate tab.</mark>\n",
    "\n",
    "Let's read the data into a DataFrame object and display the first five rows. A DataFrame object is a 2-dimensional, labeled data structure with columns that can be of different types; you can think of it like of a spreadsheet.\n",
    "\n",
    "<mark>Remember to press *Shift+Enter* to run each code cell.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first line below loads the pandas package, which provides the DataFrame structure; \n",
    "# an overview of the packages used in this notebook is provided in the \"Sources\" section\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data from file\n",
    "iris_data = pd.read_csv('iris-data.csv')\n",
    "\n",
    "# Display the first five rows\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row in the data file contains the column headers, which indicate which measurement each column represents and the unit of measurement. Each row below the header row represents an entry for a flower: four measurements and one class, which tells us the species of the flower.\n",
    "\n",
    "One of the first things we should look for is **missing data.** By looking at the \"iris-data.csv\" file, we observe that missing measurements are denoted with 'NA' in the spreadsheet. We can tell Python to automatically interpret values with 'NA' as missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this line produces no output\n",
    "iris_data = pd.read_csv('iris-data.csv', na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it's always a good idea to look at the **distribution** of the data â€” especially to identify potential **outliers**. Let's start by printing out some summary statistics about the numerical attributes of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot summary statistics of the data set\n",
    "iris_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get some useful pieces of information from this table. For example, we observe that five `petal_width_cm` entries are missing. However, identifying outliers and errors in a large table of numbers is difficult; some **visualization** of the data would be helpful. \n",
    "\n",
    "For this, let's set up the notebook so we can plot inside of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line tells the notebook to show plots inside of the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick way to obtain an overview of the data is to plot **histograms** for the numerical attributes. A histogram shows the number of data points (on the vertical axis) for which a selected attribute falls in a given value range (on the horizontal axis). Histograms reveal the distribution of data and can indicate the presence of outliers or of multiple classes in the data. Here is the histogram of the petal length attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data['petal_length_cm'].hist()\n",
    "plt.xlabel('petal_length_cm')\n",
    "plt.ylabel('number of samples')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful way to visualize data are **scatterplots**. A scatterplot displays the relationship between two numerical attributes by showing the data as a collection of points; the x- and y-coordinate of each point are the values of the two selected attributes for that point. In the following plot, we use petal length and petal width as attributes, and additionaly color each point to indicate the class it belongs to. You might already observe an issue with our data set in the chart below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=\"petal_length_cm\", y=\"petal_width_cm\",data=iris_data,hue='class')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine histograms and scatterplots to create a **scatterplot matrix**. Scatterplot matrices plot the histograms of each column along the diagonal, and a matrix of scatterplots for the combination of any two attributes. They make for an efficient tool to look for errors in our data across multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Plotting the scatterplot matrix will take a moment. \n",
    "# For plotting, we temporarily ignore the rows with 'NA' values \n",
    "\n",
    "sb.pairplot(iris_data.dropna())\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot matrix becomes even more informative if we again use colors to indicate the classes, allowing us see some further issues with the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Plotting the scatterplot matrix will take a moment. \n",
    "\n",
    "sb.pairplot(iris_data.dropna(),hue='class')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this chart, the diagonal shows so-called \"density plots\" to visualize the distributions of each feature (e.g., sepal width) for all classes simultaneously. A density plot is a variation of a histogram that uses a statistical smoothing technique to estimate a smooth shape of the distribution.\n",
    "\n",
    "<mark>Please pause here and take a moment to analyze the charts.</mark>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Question 2: Which potential issues do you notice in the data? Write down your observations before moving on to the next step.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tidy the data\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "So far, we could observe several issues with our data set. Issues include the wrong number of classes, potentially erroneous outliers in the measurements, and missing values. In all these cases, we need to figure out what to do. Let's walk through the issues one by one and fix them before proceeding with the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. There are five classes when there should only be three.\n",
    "\n",
    "Some classes are obviusly mislabeled: Some `Iris-versicolor` entries lack the `Iris-` prefix, while the other extraneous class, `Iris-setossa`, is simply a typo. We fix these errors in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the mislabeled classes\n",
    "iris_data.loc[iris_data['class'] == 'versicolor', 'class'] = 'Iris-versicolor'\n",
    "iris_data.loc[iris_data['class'] == 'Iris-setossa', 'class'] = 'Iris-setosa'\n",
    "\n",
    "# Checking that only the correct three class types remain\n",
    "iris_data['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. There are some potentially erroneous outliers. \n",
    "\n",
    "Fixing outliers can be tricky, because it's rarely clear whether the outlier was caused by measurement error, recording the data in improper units, or if the outlier is a real anomaly. If we decide to exclude any data, we need to make sure to document what data we excluded and provide solid reasoning for excluding that data. \n",
    "\n",
    "Here we observe some clear outliers in the measurements that may be erroneous: one `sepal_width_cm` entry for `Iris-setosa` falls well outside its normal range; and several `sepal_length_cm` entries for `Iris-versicolor` are near-zero: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "# Plot the histogram of `sepal_width_cm` measurements for `Iris-setosa`\n",
    "iris_data.loc[iris_data['class'] == 'Iris-setosa', 'sepal_width_cm'].hist()\n",
    "plt.xlabel('sepal_width_cm for Iris-setosa')\n",
    "plt.ylabel('number of samples')\n",
    ";\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "# Plot the histogram of `sepal_length_cm` measurements for `Iris-versicolor`\n",
    "iris_data.loc[iris_data['class'] == 'Iris-versicolor', 'sepal_length_cm'].hist()\n",
    "plt.xlabel('sepal_length_cm for Iris-versicolor')\n",
    "plt.ylabel('number of samples')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix these outliers. In the case of the one anomalous `sepal_width_cm` entry for `Iris-setosa`, we decide to remove that specific entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep only 'Iris-setosa' rows for which the sepal width is equal or greater than 2.5 cm\n",
    "iris_data = iris_data.loc[(iris_data['class'] != 'Iris-setosa') | (iris_data['sepal_width_cm'] >= 2.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the `sepal_length_cm` entries for `Iris-versicolor` that are near-zero, we take a look at the suspect entries and notice that they seem to be off by two orders of magnitude, as if they had been recorded in meters instead of centimeters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Iris-versicolor rows with a sepal length below 1 cm\n",
    "iris_data.loc[(iris_data['class'] == 'Iris-versicolor') &\n",
    "              (iris_data['sepal_length_cm'] < 1.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to adjust the entries based on this assumption, but keep track of our choice to be able to revise it later if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume near-zeor sepal_length_cm entries for Iris versicolor were recorded in meters instead of centimeters\n",
    "# and convert them to centimeters by multiplying with 100\n",
    "iris_data.loc[(iris_data['class'] == 'Iris-versicolor') &\n",
    "              (iris_data['sepal_length_cm'] < 1.0),\n",
    "              'sepal_length_cm'] *= 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. There are some rows with missing values.\n",
    "\n",
    "Let's take a look at these rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all rows which contain missing values\n",
    "iris_data.loc[(iris_data['sepal_length_cm'].isnull()) |\n",
    "              (iris_data['sepal_width_cm'].isnull()) |\n",
    "              (iris_data['petal_length_cm'].isnull()) |\n",
    "              (iris_data['petal_width_cm'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would not be ideal to exclude these rows considering they all belong to the `Iris-setosa` class. Since it seems like the missing data is systematic â€” all of the missing values are in the same column for the same *Iris* type â€” this error could potentially bias our analysis.\n",
    "\n",
    "One way to deal with missing data is **mean imputation**: If we know that the values for a measurement fall in a certain range, we can fill in empty values with the average of that measurement. Besides the mean, using the median or zero can be reasonable choices. Let's use the mean here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean petal width for Iris setosa\n",
    "average_petal_width = iris_data.loc[iris_data['class'] == 'Iris-setosa', 'petal_width_cm'].mean()\n",
    "\n",
    "# Fill missing Iris setosa petal width values with the mean value\n",
    "iris_data.loc[(iris_data['class'] == 'Iris-setosa') &\n",
    "              (iris_data['petal_width_cm'].isnull()),\n",
    "              'petal_width_cm'] = average_petal_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned the data, we don't want to repeat this process every time we work with the data set. Let's save the tidied data file *as a separate file* and work directly with that data file from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write cleaned data set to new csv (comma-separated values) file\n",
    "iris_data.to_csv('iris-data-clean.csv', index=False)\n",
    "\n",
    "# Load cleaned data into new DataFrame object\n",
    "iris_data_clean = pd.read_csv('iris-data-clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go on, let's summarize some general takeaways related to tidying the data:\n",
    "\n",
    "* Make sure the data is labeled properly\n",
    "* Check that the data falls within the expected range, using domain knowledge whenever possible to define that expected range\n",
    "* Deal with missing data: replace it if you can; otherwise drop it\n",
    "* Never \"fix\" the data manually but instead use code as a record of how you modified the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory analysis\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "Exploratory analysis is the step where we start delving deeper into the data set beyond the outliers and errors to answer questions such as:\n",
    "\n",
    "* How is the data distributed?\n",
    "* Are there any correlations in the data?\n",
    "* Are there any factors that explain these correlations?\n",
    "\n",
    "Let's return to the scatterplot matrix that we used earlier and take a look at the cleaned data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(iris_data_clean)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is normally distributed (bell-shaped) for the most part, which is great news if we plan on using any modeling methods that assume normally distributed data. But there seem to be some clusters in the petal measurements, which we suspect are related to the different Iris species. Let's color code the data by the class again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(iris_data_clean, hue='class')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the grouping of the petal measurements is related to the different species. This is actually great news for our classification task since it means that the petal measurements will facilitate distinguishing between the Iris types. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Question 3: Do you notice anything that might make it difficult to distinguish between the three Iris species? Hint: Notice where the groups of datapoints are in the scatter plots. </div>\n",
    "\n",
    "There are also correlations between petal length and petal width, as well as between sepal length and sepal width. These correlations suggest that longer flower petals (or sepals) also tend to be wider, which seems realistic. \n",
    "\n",
    "Now we have a better understanding of the data we are dealing with. Let's finally get to some modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Classification\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "You might be surprised that it took us so long to get to the actual modeling step. In general, data preparation tends to be by far the [most time-consuming](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/) step in data science, and it is a vital one: If we had jumped straight to the modeling, we would have created a faulty classification model. Remember to always check your data first: **Bad data leads to bad models.** \n",
    "\n",
    "Before we select and train a classification model, we need to **split the data into training and testing sets:**\n",
    "- A **training set** is a random subset of the data that we use to train our models.\n",
    "- A **testing set** is a random subset of the data (mutually exclusive from the training set) that we use to validate our models on data they have not seen before.\n",
    "\n",
    "Let's set up our data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're using all four measurements as inputs to the model\n",
    "# Note that scikit-learn expects each entry to be a list of values, e.g.,\n",
    "# [ [val1, val2, val3],\n",
    "#   [val1, val2, val3],\n",
    "#   ... ]\n",
    "# such that our input data set is represented as a list of lists\n",
    "\n",
    "# We can extract the data in this format from the DataFrame like this:\n",
    "all_inputs = iris_data_clean[['sepal_length_cm', 'sepal_width_cm',\n",
    "                             'petal_length_cm', 'petal_width_cm']].values\n",
    "# Make sure to not mix up the order of the entries\n",
    "\n",
    "# Similarly, we can extract the class labels\n",
    "all_labels = iris_data_clean['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that the representation is correct for a random input data point n\n",
    "n = 42\n",
    "\n",
    "print(all_inputs[n],all_labels[n])\n",
    "iris_data_clean.loc[[n]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks fine! Now our data is ready to be split. We split the data randomly using the method \"train_test_split\" from the **scikit-learn** library, the essential machine learning package in Python. We can specify what fraction of the data should be used for the test set using the parameter `test_size`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(training_inputs,\n",
    " testing_inputs,\n",
    " training_classes,\n",
    " testing_classes) = train_test_split(all_inputs, all_labels, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data split, we can start fitting models to our data. We will use a **decision tree classifier**: In their simplest form, decision tree classifiers ask a series of Yes/No questions about the data â€” each time getting closer to finding out the class of each entry â€” until they either classify the data set perfectly or simply can't differentiate a set of entries. \n",
    "\n",
    "\n",
    "Note: There are several [parameters](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) that we can tune for decision tree classifiers, but for now we use a basic decision tree classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "decision_tree_classifier.fit(training_inputs, training_classes)\n",
    "\n",
    "# Validate the classifier on the testing set using classification accuracy\n",
    "decision_tree_classifier.score(testing_inputs, testing_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy: Our model achieves **97% classification accuracy** without much effort. However, there's a catch: The split of the data set was done randomly; depending on how our training and testing set is sampled, our model can achieve anywhere from 80% to 100% accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracies = []\n",
    "\n",
    "# Split data set randomly 1000 times, and train and test the model\n",
    "for repetition in range(1000):\n",
    "    (training_inputs,\n",
    "     testing_inputs,\n",
    "     training_classes,\n",
    "     testing_classes) = train_test_split(all_inputs, all_labels, test_size=0.25)\n",
    "    \n",
    "    decision_tree_classifier = DecisionTreeClassifier()\n",
    "    decision_tree_classifier.fit(training_inputs, training_classes)\n",
    "    classifier_accuracy = decision_tree_classifier.score(testing_inputs, testing_classes)\n",
    "    model_accuracies.append(classifier_accuracy)\n",
    "\n",
    "# Display the accuracy distribution obtained    \n",
    "plt.hist(model_accuracies)\n",
    "plt.xlabel('model accuracy')\n",
    "plt.ylabel('number of repetitions')\n",
    "left, right = plt.xlim() \n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's obviously a problem that our model performs quite differently depending on the subset of the data it's trained on. A better way to evaluate the model is to use **cross-validation**.\n",
    "\n",
    "## Step 6: Evaluation with cross-validation\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "A better approach to evaluate our model is to perform a ***k*-fold cross-validation**, which works as follows: Split the original data set into *k* subsets called *folds*; use one of the folds (the \"test data\") for evaluation, and train on the rest of the folds (the \"trainig data\"). Repeat *k* times such that each fold is used as the testing set exactly once:\n",
    "\n",
    "<img src=\"images/Diagram_K-fold_cross_validation.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "10-fold cross-validation is the most common choice. We can perform 10-fold cross-validation on our model with the code below. The result is an array containing the 10 evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "k = 10\n",
    "\n",
    "# cross_val_score returns a list of the scores, which we can visualize\n",
    "# to get a reasonable estimate of our classifier's performance\n",
    "cv_scores = cross_val_score(decision_tree_classifier, all_inputs, all_labels, cv=k)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `cross_val_score` method actually performs a **stratified *k*-fold cross-validation**. Stratified *k*-fold keeps the class proportions the same across all of the folds, which is vital for ensuring that the testing is performed on a representative subset of the data set.\n",
    "\n",
    "Now we have a more consistent rating of our classifier's general classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {:.3f}'.format(np.mean(cv_scores)))\n",
    "plt.xlabel('model accuracy')\n",
    "plt.ylabel('number of folds')\n",
    "plt.xlim(left, right) \n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! We finally have our demo classifier in a complete and reproducible machine learning pipeline. We've met the success criteria that we set from the beginning (>90% accuracy), and our pipeline is flexible enough to handle new inputs or flowers when that data set is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Question 4: Would you expect the classification accuracy to deteriorate considerably if we did not correct for the outliers in the data? Why / why not?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "Based on a notebook by [Randal S. Olson](http://www.randalolson.com/). \n",
    "\n",
    "Sources for pictures:\n",
    "* iris-types.png: https://gadictos.com/iris-data-classification-using-neural-net/\n",
    "* iris_petal_sepal.png: https://holgerbrandl.github.io/kotlin4ds_kotlin_night_frankfurt/krangl_example_report.html\n",
    "* Diagram_K-fold_cross_validation.png: https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "\n",
    "### Python packages used\n",
    "\n",
    "This notebook uses several standard Python packages. These are:\n",
    "\n",
    "* **pandas**: Provides the \"DataFrame\" structure to store data in memory and work with it easily and efficiently. DataFrame is a 2-dimensional labeled data structure with columns of potentially different types; you can think of it like a spreadsheet.\n",
    "* **matplotlib**: Basic plotting library in Python; most other Python plotting libraries are built on top of it.\n",
    "* **Seaborn**: Advanced statistical plotting library.\n",
    "* **scikit-learn**: The essential Machine Learning package in Python.\n",
    "* **NumPy**: Provides a fast numerical array structure and helper functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
